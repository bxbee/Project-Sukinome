Big data 4v
data processing (Batch and Streming )
<p>Types of data ---   1.Structured data  2.Semistructure 3.  Unstructured data 4. disk -- data stored in block and sector</p>
<p>About apache beam</p>
<p>Run apache beam cluster on gcp cloud run apachebeam runtime on gcp</p>
<p>1.Top level apache open source projects</p>
<p>started at 2016</p>
<p>Apache beam is a unified programming model that can build portable</p>
<p>Beam=batch+streamming</p>
<p>Beam supports Python,java,go lang</p>



<h1>How Apache beam Works?</h1>
<p>It uses Map Reduce Model</p>
<p>Google developed map reduces models</p>
<p>Independently Hadoop born based on map reduce concept</p>
<p>Hardoop is open source ,can be installed in any Linux Platform</p>
<p>Flume,Flick and spark is used in real time case studies</p>
<p>Other apache project you can use Hbase,hive,pig and oozie</p>


<h1>Cloud Dataflow Apache beam Cloud version on Google Cloud Program</h1>


<h3>Big Data uses distributed Systems</h3>
<p> hadroop</p>
HDFS (Hardoop distributed File system)
<h4>Example </h4>
<p>500*1024</p>





